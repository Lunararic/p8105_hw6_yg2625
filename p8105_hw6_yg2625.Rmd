---
title: "p8105_hw6_yg2625"
author: "Yue Gu"
date: "November 25, 2018"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Library
```{r, message = F}
library(tidyverse)
```

# Problem 1
## Import data
```{r, message = FALSE}
homi_raw = read_csv("https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv")
head(homi_raw, 10)
```

## Data manipulation
* Create a city_state variable, and a binary variable
* Omit cities Dallas, TX; Phoenix, AZ; and Kansas City, MO; Tulsa, AL
* Modifiy victim_race to have categories white and non-white
* Transform victim_age as numeric
```{r, message = FALSE}
homi_create = 
  homi_raw %>% 
  mutate(city_state = paste(city, state, sep = ", "),
         solved = ifelse(disposition == "Closed without arrest" | disposition == "Open/No arrest", 0, 1)) %>% 
  filter(city_state != "Dallas, TX" , city_state != "Phoenix, AZ", city_state != "Kansas City, MO", city_state != "Tulsa, AL") %>% 
  mutate(victim_race = ifelse(victim_race == "White", "white", "nonwhite"),
         victim_race = fct_relevel(victim_race, "white"),
         victim_age = as.numeric(victim_age))

class(homi_create$victim_age)
class(homi_create$victim_race)

```
As required, binary variable *solved* have value 0 if the case is unsolved, have value 1 if the case is solved, *victim_race* have categories white and non-white as factors and *victim_age* are numeric.

## Fit regression
* For the city of Baltimore, MD, use the glm function to fit a logistic regression with resolved vs unresolved as the outcome and victim age, sex and race as predictors
* Save the output of glm as an R object
```{r}
fit_log_balt = 
  homi_create %>% 
  filter(city_state == "Baltimore, MD") %>% 
  glm(solved ~ victim_age + victim_sex + victim_race, data = ., family = binomial())
  
```

* Apply the broom::tidy to this object
* Obtain the estimate and confidence interval of the adjusted odds ratio for solving homicides comparing non-white victims to white victims keeping all other variables fixed
```{r}
fit_log_balt %>% 
  broom::tidy() %>%
  mutate(OR = exp(estimate),
         OR_low = exp(estimate - qnorm(1-0.05/2)*std.error),
         OR_high = exp(estimate + qnorm(1-0.05/2)*std.error)) %>%
  select(term, estimate, OR, OR_low, OR_high) %>% 
  knitr::kable(digits = 3)
```

With the output, we could know the adjusted odds ratio for solving homicides comparing non-white victims to white victims is 0.441 keep all else fixed. And we are 95% confident that the adjusted odds ratio will fall in the range from 0.313 to 0.620.


* Run glm for each of the cities in your dataset, and extract the adjusted odds ratio (and CI) for solving homicides comparing non-white victims to white victims
```{r}
fit_log_all =
  homi_create %>% 
  group_by(city_state) %>% 
  nest() %>% 
  mutate(models = map(data, ~glm(solved ~ victim_age + victim_sex + victim_race, data = ., family = binomial())),
         models = map(models, broom::tidy)) %>% 
  select(-data) %>% 
  unnest() %>% 
  filter(term == "victim_racenonwhite") %>%
  mutate(OR = exp(estimate),
         OR_low = exp(estimate - qnorm(1-0.05/2)*std.error),
         OR_high = exp(estimate + qnorm(1-0.05/2)*std.error)) %>% 
  select(-term, -std.error, -p.value, - statistic)

# show the first 10 outputs of the tidies model dataset as dataframe
head(fit_log_all, 10) %>% 
  knitr::kable(digits = 3)
```

* Create a plot that shows the estimated ORs and CIs for each city. Organize cities according to estimated OR, and comment on the plot
```{r}
fit_log_all %>% 
  mutate(city_state = forcats::fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = OR)) +
  geom_point() +
  geom_errorbar(aes(ymin = OR_low, ymax = OR_high)) +
  labs(title = "Estimated ORs and CIs for each city",
       x = "City, State",
       y = "Estimated Adjusted OR") +
  theme(axis.text.x = element_text(angle = 80, hjust = 1))
```

**Comments:**   
From the plot, we could observe that Boston has the lowest adjusted OR and Tampa has the highest one. Most of the cities has adjusted OR lower than 1 except for Durham, Birmingham and Tampa. For those cities with adjusted OR lower than 1, it indicates that the resolved cases among non-whites have lower odds compared to the resolved cases among the whites. In Durham, Birmingham and Tampa, since their adjusted OR are greater or equal to 1, it indicates the resolved cases among non-whites have higher or equal odds compared to the resolved cases among the whites.  

By observing the CIs, we could find that Houston, Durham and Tampa have relatively high-range intervals, meaning the true adjusted OR may fall in the wider range compared to other cities and we need further analysis combined with the observations to p-value to make reasonable conclusions.


# Problem 2
## Load and clean the data
```{r, message = FALSE}
birth_tidy = read_csv("./data/birthweight.csv") %>% 
  janitor::clean_names() %>%
  mutate(babysex = as.factor(babysex),
         frace = as.factor(frace),
         malform = as.factor(malform),
         mrace = as.factor(mrace))

anyNA(birth_tidy)
head(birth_tidy, 10)

```

With the output from anyNA, we know there is no missing values in the dataset, and we converted all numeric to factor where appropriate.

## Propose a regression model for birthweight
Using **Backward Elimination** by starting with all predictors in the model and remove the predictor with the highest p-value > alpha
```{r}
# fit a regression using all predictors and do elimataion with alpha = 0.05
mult.fit = lm(bwt ~ ., data = birth_tidy)
summary(mult.fit)
# take out 3 predictors because of singularities
step1 = update(mult.fit, . ~ . -pnumlbw -pnumsga -wtgain)
summary(step1)
# take out frace since frace factor 8 has the highest p-value
step2 = update(step1, . ~ . -frace)
summary(step2)
# take out malform
step3 = update(step2, . ~ . -malform)
summary(step3)
# take out ppbmi
step4 = update(step3, . ~ . -ppbmi)
summary(step4)
# take out momage
step5 = update(step4, . ~ . -momage)
summary(step5)
# take out menarche
step6 = update(step5, . ~ . -menarche)
summary(step6)
# take out fincome
step7 = update(step6, . ~ . -fincome)
summary(step7)
# take out mrace
step8 = update(step7, . ~ . -mrace)
summary(step8)
## Since adjusted R-square got lower, we need to include mrace
```

The backward elimination process is shown above in comments, the main process is eliminating predictors with the highest p-value > 0.05 until no predictors is non-significant. and the final chosen model including predictors shown below:
```{r}
final.fit = lm(bwt ~ babysex + bhead + blength + delwt + gaweeks + mheight + parity + ppwt + smoken + mrace, data = birth_tidy)
summary(final.fit)
```

## Show a plot of model residuals against fitted values

```{r}
birth_tidy %>% 
  modelr::add_residuals(final.fit) %>% 
  modelr::add_predictions(final.fit) %>% 
  ggplot(aes(x = pred, y = resid)) +
  geom_point() +
  geom_hline(yintercept = 0, color = "red") +
  labs(title = "Model Residuals vs. Fitted Values",
       x = "Fitted Values",
       y = "Residuals")
  
```
By the plot, we could see that although there are several extremely high residual points, most of the datapoints generally spread out around the 0 line and the linear is reasonable.


## Compare your model to two others
* One using length at birth and gestational age as predictors
* One using head circumference, length, sex, and all interactions between these


